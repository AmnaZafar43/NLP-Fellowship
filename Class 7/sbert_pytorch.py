# -*- coding: utf-8 -*-
"""SBERT_Pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_V7hRHE-ZnnHm2reVgZoi_PUbWxjkHY_
"""

!pip install -Uqqq pip --progress-bar off
!pip install -qqq sentence-transformers==2.2.2 --progress-bar off

from sentence_transformers import SentenceTransformer, util

sentence_1 = "Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and crypto.'"
sentence_2 = "One of the biggest bull traps I've ever seen"

model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")

model.max_seq_length

corpus=[
    "Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and crypto.'",
    "One of the biggest bull traps I've ever seen.",
    "How I sleep knowing ethereum is going to 10k in 2025.",
    "Bitcoin is a scam.",
    "Is The $BTC BOTTOM In? Are you team BULL or team BEAR? Do you have data to prove your point?",
    "I will stop bragging about calling the top when I start bragging about calling the bottom. #bitcoin",
    "First powerlifting meet of year and a new squat PR!!",
    "On January 9th, 2023, the American Academy of Pediatrics published new guidlines treating obesity in children adolescents.",
    "What's worse, someone dropping the bar from the top of deadlift or not putting their shopping cart away?",
    "The sport of powerlifting includes squart bench and deadlift. But the concept of powerlifting is Force = Mass x Acceleration."
]

corpus_embeddings = model.encode(corpus,show_progress_bar=True, convert_to_tensor=True)

corpus_embeddings.shape

corpus_embeddings[0]

query = "How high will bitcoin go?"

query_embeddidng = model.encode(query,convert_to_tensor=True)

query_embeddidng

# since our query is very similary to first one so it give good result
util.cos_sim(query_embeddidng,corpus_embeddings[0])

# since our query not similar to last one in corpus so it gives -ve result
util.cos_sim(query_embeddidng,corpus_embeddings[9])

sentence1_embedding = model.encode(sentence_1,convert_to_tensor=True)
sentence2_embedding = model.encode(sentence_2,convert_to_tensor=True)

util.cos_sim(sentence1_embedding,sentence2_embedding)

result = util.semantic_search(query_embeddidng,corpus_embeddings)
result

# Train your own model


from sentence_transformers import SentencesDataset, InputExample, losses
from torch.utils.data import DataLoader

dataset = SentencesDataset([
    InputExample(
        texts = [
            "Bitcoin is up 34% since Bank of England Governor said 'Be prepared to lose all your money in BTC and crypto.'",
            "One of the biggest bull traps I've ever seen"
        ],label = 0.9
    )
],model)

dataloader = DataLoader(dataset, shuffle = True)
loss = losses.CosineSimilarityLoss(model=model)

save_path = "trained_model"

model.fit(train_objectives=[(dataloader,loss)], epochs=10,warmup_steps=10, output_path=save_path)

trained_model = SentenceTransformer(save_path)

sentence1_embedding = trained_model.encode(sentence_1,convert_to_tensor=True)
sentence2_embedding = trained_model.encode(sentence_2,convert_to_tensor=True)

util.cos_sim(sentence1_embedding,sentence2_embedding)